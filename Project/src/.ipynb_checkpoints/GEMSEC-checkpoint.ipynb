{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import igraph\n",
    "import networkx as nx\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(path, filename, weighted = False, directed = False):\n",
    "    with open(path + filename, \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        edges  = list(reader)[1:]\n",
    "    edges = [(int(edge[0]),int(edge[1])) for edge in edges]\n",
    "    Nb_nodes = max([max(nodes) for nodes in edges])+1\n",
    "    if directed : \n",
    "        g = igraph.Graph(directed = True)\n",
    "    else :\n",
    "        g = igraph.Graph()\n",
    "    g.add_vertices(Nb_nodes)\n",
    "    g.add_edges(edges)\n",
    "    if weighted :\n",
    "        g.es[\"weight\"] = g.similarity_jaccard(pairs = edges)\n",
    "    else :\n",
    "        g.es[\"weight\"] = 1\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '..\\data'\n",
    "g_dir =  create_graph(path,'\\HR_edges.csv', weighted = False, directed = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_generator(overlap_weighting, graph):\n",
    "    \"\"\"\n",
    "    Function to generate weight for all of the edges.\n",
    "    \"\"\"\n",
    "    edges = [e.tuple for e in graph.es ]\n",
    "    if overlap_weighting == \"normalized_overlap\":\n",
    "        weights = graph.similarity_jaccard(pairs = edges)\n",
    "        weights = {e: weights[i] for i,e in enumerate(edges)}\n",
    "        weights_prime = {(e[1], e[0]): value for e, value in weights.items()}\n",
    "        weights.update(weights_prime)\n",
    "    else:\n",
    "        weights = {e: 1 for e in edges}\n",
    "        weights_prime = {(e[1], e[0]): value for e, value in weights.items()}\n",
    "        weights.update(weights_prime)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = overlap_generator(\"normalized_overlap\", g_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWalker:\n",
    "    \"\"\"\n",
    "    Class to generate vertex sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, graph, repetitions, length):\n",
    "        print(\"Model initialization started.\")\n",
    "        self.graph = graph\n",
    "        self.nodes = [node.index for node in self.graph.vs]\n",
    "        self.repetitions = repetitions\n",
    "        self.length = length\n",
    "\n",
    "    def small_walk(self, start_node):\n",
    "        \"\"\"\n",
    "        Generate a node sequence from a start node.\n",
    "        \"\"\"\n",
    "        return self.graph.random_walk(start_node, self.length)\n",
    "\n",
    "    def count_frequency_values(self):\n",
    "        \"\"\"\n",
    "        Calculate the co-occurence frequencies.\n",
    "        \"\"\"\n",
    "        raw_counts = [node for walk in self.walks for node in walk]\n",
    "        counts = Counter(raw_counts)\n",
    "        self.degrees = [counts[i] for i in range(len(self.nodes))]\n",
    "\n",
    "    def do_walks(self):\n",
    "        \"\"\"\n",
    "        Do a series of random walks.\n",
    "        \"\"\"\n",
    "        self.walks = []\n",
    "        for rep in range(0, self.repetitions):\n",
    "            random.shuffle(self.nodes)\n",
    "            print(\" \")\n",
    "            print(\"Random walk series \" + str(rep+1) + \". initiated.\")\n",
    "            print(\" \")\n",
    "            for node in tqdm(self.nodes):\n",
    "                walk = self.small_walk(node)\n",
    "                self.walks.append(walk)\n",
    "        self.count_frequency_values()\n",
    "        return self.degrees, self.walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialization started.\n"
     ]
    }
   ],
   "source": [
    "RW = RandomWalker(graph = g_dir,repatitions = 5, length = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Random walk series 1. initiated.\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54573/54573 [00:05<00:00, 9862.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Random walk series 2. initiated.\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54573/54573 [00:05<00:00, 9721.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Random walk series 3. initiated.\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54573/54573 [00:05<00:00, 9533.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Random walk series 4. initiated.\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54573/54573 [00:05<00:00, 9918.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Random walk series 5. initiated.\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54573/54573 [00:06<00:00, 8815.88it/s] \n"
     ]
    }
   ],
   "source": [
    "degrees, walks = RW.do_walks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[34416, 36072, 40704, 9071, 48911, 50052, 53678, 17571]\n"
     ]
    }
   ],
   "source": [
    "print(degrees[11])\n",
    "print(walks[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_generation(weights, a_walk):\n",
    "    \"\"\"\n",
    "    Function to generate overlaps and indices.\n",
    "    \"\"\"\n",
    "    edges = [(a_walk[i], a_walk[i+1]) for i in range(0, len(a_walk)-1)]\n",
    "    edge_set_1 = np.array(range(0, len(a_walk)-1))\n",
    "    edge_set_2 = np.array(range(1, len(a_walk)))\n",
    "    overlaps = np.array(list(map(lambda x: weights[x], edges))).reshape((-1, 1))\n",
    "    return edge_set_1, edge_set_2, overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n",
      "[1 2 3 4 5 6 7]\n",
      "[[0.07692308]\n",
      " [0.04761905]\n",
      " [0.05681818]\n",
      " [0.05434783]\n",
      " [0.125     ]\n",
      " [0.06521739]\n",
      " [0.11764706]]\n"
     ]
    }
   ],
   "source": [
    "index_1, index_2, overlaps = index_generation(weights = weights, a_walk = walks[11])\n",
    "print(index_1)\n",
    "print(index_2)\n",
    "print(overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_input_generator(a_walk, random_walk_length, window_size):\n",
    "    \"\"\"\n",
    "    Function to generate features from a node sequence.\n",
    "    \"\"\"\n",
    "    seq_1 = [a_walk[j] for j in range(random_walk_length-window_size)]\n",
    "    seq_2 = [a_walk[j] for j in range(window_size, random_walk_length)]\n",
    "    return np.array(seq_1 + seq_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34416 36072 40704 50052 53678 17571]\n"
     ]
    }
   ],
   "source": [
    "batch_inputs = batch_input_generator(a_walk = walks[11], random_walk_length = len(walks[11]), window_size = 5)\n",
    "print(batch_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_label_generator(a_walk, random_walk_length, window_size):\n",
    "    \"\"\"\n",
    "    Function to generate labels from a node sequence.\n",
    "    \"\"\"\n",
    "    grams_1 = [a_walk[j+1:j+1+window_size] for j in range(random_walk_length-window_size)]\n",
    "    grams_2 = [a_walk[j-window_size:j] for j in range(window_size, random_walk_length)]\n",
    "    return np.array(grams_1 + grams_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36072 40704  9071 48911 50052]\n",
      " [40704  9071 48911 50052 53678]\n",
      " [ 9071 48911 50052 53678 17571]\n",
      " [34416 36072 40704  9071 48911]\n",
      " [36072 40704  9071 48911 50052]\n",
      " [40704  9071 48911 50052 53678]]\n"
     ]
    }
   ],
   "source": [
    "batch_labels = batch_label_generator(a_walk = walks[11], random_walk_length = len(walks[11]), window_size = 5)\n",
    "print(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_incrementer(step, gamma_0, gamma_final, current_gamma, num_steps):\n",
    "    if step > 1:\n",
    "        exponent = (0-np.log10(gamma_0))/float(num_steps)\n",
    "        current_gamma = current_gamma * (10 **exponent)*(gamma_final-gamma_0)\n",
    "        current_gamma = current_gamma + gamma_0\n",
    "    return current_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_modularity_calculator(graph, embedding, means):\n",
    "    \"\"\"\n",
    "    Function to calculate the GEMSEC cluster assignments.\n",
    "    \"\"\"\n",
    "    assignments = {}\n",
    "    for node in graph.vs:\n",
    "        positions = means-embedding[node.index, :]\n",
    "        values = np.sum(np.square(positions), axis=1)\n",
    "        index = np.argmin(values)\n",
    "        assignments[int(node.index)] = int(index)\n",
    "    modularity = graph.modularity(membership = assignments)\n",
    "    return modularity, assignments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
